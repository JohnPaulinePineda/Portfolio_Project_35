---
title: "Supervised Learning : Characterizing Life Expectancy Drivers Across Countries Using Model-Agnostic Interpretation Methods for Black-Box Models"
author: "John Pauline Pineda"
date: "July 15, 2023"
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: readable
    highlight: tango
    css: doc.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=15, fig.height=10)
```
# **1. Table of Contents**
|
| Description
|
##  1.1 Introduction
|
###  1.1.1 Study Objectives
|
###  1.1.2 Outcome
|
###  1.1.3 Predictors
|
##  1.2 Methodology
|
###  1.2.1 Model Formulation
|
###  1.2.2 Model Evaluation
|
###  1.2.3 Model Post-Hoc Analysis
|
##  1.3 Results
|
###  1.3.1 Data Preparation
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.1, warning=FALSE, message=FALSE}
##################################
# Loading R libraries
##################################
library(DALEX)
library(caret)
library(randomForest)
library(e1071)
library(gbm)
library(skimr)
library(corrplot)
library(lares)
library(dplyr)
library(minerva)
library(CORElearn)

##################################
# Loading source and
# formulating the analysis set
##################################
LED <- read.csv("Life_Expectancy_Data.csv",
                na.strings=c("NA","NaN"," ",""),
                stringsAsFactors = FALSE)
LED <- as.data.frame(LED)

##################################
# Performing a general exploration of the data set
##################################
dim(LED)
str(LED)
summary(LED)

##################################
# Transforming to appropriate data types
##################################
LED$YEAR <- factor(LED$YEAR,
                      levels = c("2019"))
LED$GENDER <- factor(LED$GENDER,
                      levels = c("Male","Female"))

##################################
# Reducing the range of values
# for certain numeric predictors
##################################
LED$GDP     <- LED$GDP/1000000000
LED$GNI     <- LED$GNI/1000000000
LED$PERCAP  <- LED$PERCAP/1000

##################################
# Formulating a data type assessment summary
##################################
PDA <- LED
(PDA.Summary <- data.frame(
  Column.Index=c(1:length(names(PDA))),
  Column.Name= names(PDA), 
  Column.Type=sapply(PDA, function(x) class(x)), 
  row.names=NULL)
)

```

</details>

###  1.3.2 Data Quality Assessment
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.2, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DQA <- LED

##################################
# Formulating an overall data quality assessment summary
##################################
(DQA.Summary <- data.frame(
  Column.Index=c(1:length(names(DQA))),
  Column.Name= names(DQA),
  Column.Type=sapply(DQA, function(x) class(x)),
  Row.Count=sapply(DQA, function(x) nrow(DQA)),
  NA.Count=sapply(DQA,function(x)sum(is.na(x))),
  Fill.Rate=sapply(DQA,function(x)format(round((sum(!is.na(x))/nrow(DQA)),3),nsmall=3)),
  row.names=NULL)
)

##################################
# Listing all Predictors
##################################
DQA.Predictors <- DQA[,!names(DQA) %in% c("COUNTRY","YEAR","LIFEXP")]

##################################
# Listing all numeric Predictors
##################################
DQA.Predictors.Numeric <- DQA.Predictors[,sapply(DQA.Predictors, is.numeric), drop = FALSE]

if (length(names(DQA.Predictors.Numeric))>0) {
    print(paste0("There is (are) ",
               (length(names(DQA.Predictors.Numeric))),
               " numeric descriptor variable(s)."))
} else {
  print("There are no numeric descriptor variables.")
}

##################################
# Listing all factor Predictors
##################################
DQA.Predictors.Factor <- DQA.Predictors[,sapply(DQA.Predictors, is.factor), drop = FALSE]

if (length(names(DQA.Predictors.Factor))>0) {
    print(paste0("There is (are) ",
               (length(names(DQA.Predictors.Factor))),
               " factor descriptor variable(s)."))
} else {
  print("There are no factor descriptor variables.")
}

##################################
# Formulating a data quality assessment summary for factor Predictors
##################################
if (length(names(DQA.Predictors.Factor))>0) {

  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = x[!(x %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return("x"),
           return(usm[tabsm == max(tabsm)]))
  }

  (DQA.Predictors.Factor.Summary <- data.frame(
  Column.Name= names(DQA.Predictors.Factor),
  Column.Type=sapply(DQA.Predictors.Factor, function(x) class(x)),
  Unique.Count=sapply(DQA.Predictors.Factor, function(x) length(unique(x))),
  First.Mode.Value=sapply(DQA.Predictors.Factor, function(x) as.character(FirstModes(x)[1])),
  Second.Mode.Value=sapply(DQA.Predictors.Factor, function(x) as.character(SecondModes(x)[1])),
  First.Mode.Count=sapply(DQA.Predictors.Factor, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Predictors.Factor, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  Unique.Count.Ratio=sapply(DQA.Predictors.Factor, function(x) format(round((length(unique(x))/nrow(DQA.Predictors.Factor)),3), nsmall=3)),
  First.Second.Mode.Ratio=sapply(DQA.Predictors.Factor, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  row.names=NULL)
  )

}

##################################
# Formulating a data quality assessment summary for numeric Predictors
##################################
if (length(names(DQA.Predictors.Numeric))>0) {

  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = na.omit(x)[!(na.omit(x) %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return(0.00001),
           return(usm[tabsm == max(tabsm)]))
  }

  (DQA.Predictors.Numeric.Summary <- data.frame(
  Column.Name= names(DQA.Predictors.Numeric),
  Column.Type=sapply(DQA.Predictors.Numeric, function(x) class(x)),
  Unique.Count=sapply(DQA.Predictors.Numeric, function(x) length(unique(x))),
  Unique.Count.Ratio=sapply(DQA.Predictors.Numeric, function(x) format(round((length(unique(x))/nrow(DQA.Predictors.Numeric)),3), nsmall=3)),
  First.Mode.Value=sapply(DQA.Predictors.Numeric, function(x) format(round((FirstModes(x)[1]),3),nsmall=3)),
  Second.Mode.Value=sapply(DQA.Predictors.Numeric, function(x) format(round((SecondModes(x)[1]),3),nsmall=3)),
  First.Mode.Count=sapply(DQA.Predictors.Numeric, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Predictors.Numeric, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  First.Second.Mode.Ratio=sapply(DQA.Predictors.Numeric, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  Minimum=sapply(DQA.Predictors.Numeric, function(x) format(round(min(x,na.rm = TRUE),3), nsmall=3)),
  Mean=sapply(DQA.Predictors.Numeric, function(x) format(round(mean(x,na.rm = TRUE),3), nsmall=3)),
  Median=sapply(DQA.Predictors.Numeric, function(x) format(round(median(x,na.rm = TRUE),3), nsmall=3)),
  Maximum=sapply(DQA.Predictors.Numeric, function(x) format(round(max(x,na.rm = TRUE),3), nsmall=3)),
  Skewness=sapply(DQA.Predictors.Numeric, function(x) format(round(skewness(x,na.rm = TRUE),3), nsmall=3)),
  Kurtosis=sapply(DQA.Predictors.Numeric, function(x) format(round(kurtosis(x,na.rm = TRUE),3), nsmall=3)),
  Percentile25th=sapply(DQA.Predictors.Numeric, function(x) format(round(quantile(x,probs=0.25,na.rm = TRUE),3), nsmall=3)),
  Percentile75th=sapply(DQA.Predictors.Numeric, function(x) format(round(quantile(x,probs=0.75,na.rm = TRUE),3), nsmall=3)),
  row.names=NULL)
  )

}

##################################
# Identifying potential data quality issues
##################################

##################################
# Checking for missing observations
##################################
if ((nrow(DQA.Summary[DQA.Summary$NA.Count>0,]))>0){
  print(paste0("Missing observations noted for ",
               (nrow(DQA.Summary[DQA.Summary$NA.Count>0,])),
               " variable(s) with NA.Count>0 and Fill.Rate<1.0."))
  DQA.Summary[DQA.Summary$NA.Count>0,]
} else {
  print("No missing observations noted.")
}

##################################
# Checking for zero or near-zero variance Predictors
##################################
if (length(names(DQA.Predictors.Factor))==0) {
  print("No factor Predictors noted.")
} else if (nrow(DQA.Predictors.Factor.Summary[as.numeric(as.character(DQA.Predictors.Factor.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Predictors.Factor.Summary[as.numeric(as.character(DQA.Predictors.Factor.Summary$First.Second.Mode.Ratio))>5,])),
               " factor variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Predictors.Factor.Summary[as.numeric(as.character(DQA.Predictors.Factor.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance factor Predictors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Predictors.Numeric))==0) {
  print("No numeric Predictors noted.")
} else if (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$First.Second.Mode.Ratio))>5,])),
               " numeric variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance numeric Predictors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Predictors.Numeric))==0) {
  print("No numeric Predictors noted.")
} else if (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Unique.Count.Ratio))<0.01,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Unique.Count.Ratio))<0.01,])),
               " numeric variable(s) with Unique.Count.Ratio<0.01."))
  DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Unique.Count.Ratio))<0.01,]
} else {
  print("No low variance numeric Predictors due to low unique count ratio noted.")
}

##################################
# Checking for skewed Predictors
##################################
if (length(names(DQA.Predictors.Numeric))==0) {
  print("No numeric Predictors noted.")
} else if (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))<(-3),])>0){
  print(paste0("High skewness observed for ",
  (nrow(DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))<(-3),])),
  " numeric variable(s) with Skewness>3 or Skewness<(-3)."))
  DQA.Predictors.Numeric.Summary[as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))>3 |
                                 as.numeric(as.character(DQA.Predictors.Numeric.Summary$Skewness))<(-3),]
} else {
  print("No skewed numeric Predictors noted.")
}

```

</details>

###  1.3.3 Data Preprocessing
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.3.1, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- LED

##################################
# Gathering descriptive statistics
##################################
(DPA_Skimmed <- skim(DPA))
```

```{r section_1.3.3.2, warning=FALSE, message=FALSE, fig.width=15, fig.height=2}
##################################
# Outlier Treatment
##################################

##################################
# Listing all Predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("COUNTRY","YEAR","LIFEXP")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

##################################
# Identifying outliers for the numeric predictors
##################################
OutlierCountList <- c()

for (i in 1:ncol(DPA.Predictors.Numeric)) {
  Outliers <- boxplot.stats(DPA.Predictors.Numeric[,i])$out
  OutlierCount <- length(Outliers)
  OutlierCountList <- append(OutlierCountList,OutlierCount)
  OutlierIndices <- which(DPA.Predictors.Numeric[,i] %in% c(Outliers))
  print(
  ggplot(DPA.Predictors.Numeric, aes(x=DPA.Predictors.Numeric[,i])) +
  geom_boxplot() +
  theme_bw() +
  theme(axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) +
  xlab(names(DPA.Predictors.Numeric)[i]) +
  labs(title=names(DPA.Predictors.Numeric)[i],
       subtitle=paste0(OutlierCount, " Outlier(s) Detected")))
}

##################################
# Formulating the histogram
# for the numeric predictors
##################################

for (i in 1:ncol(DPA.Predictors.Numeric)) {
  Median <- format(round(median(DPA.Predictors.Numeric[,i],na.rm = TRUE),2), nsmall=2)
  Mean <- format(round(mean(DPA.Predictors.Numeric[,i],na.rm = TRUE),2), nsmall=2)
  Skewness <- format(round(skewness(DPA.Predictors.Numeric[,i],na.rm = TRUE),2), nsmall=2)
  print(
  ggplot(DPA.Predictors.Numeric, aes(x=DPA.Predictors.Numeric[,i])) +
  geom_histogram(binwidth=1,color="black", fill="white") +
  geom_vline(aes(xintercept=mean(DPA.Predictors.Numeric[,i])),
            color="blue", size=1) +
    geom_vline(aes(xintercept=median(DPA.Predictors.Numeric[,i])),
            color="red", size=1) +
  theme_bw() +
  ylab("Count") +
  xlab(names(DPA.Predictors.Numeric)[i]) +
  labs(title=names(DPA.Predictors.Numeric)[i],
       subtitle=paste0("Median = ", Median,
                       ", Mean = ", Mean,
                       ", Skewness = ", Skewness)))
}

##################################
# Investigating distributional anomalies
# observed for several predictors 
##################################
(INFMOR_Unique <- DPA %>%
  group_by(INFMOR) %>%
  summarize(Distinct_INFMOR = n_distinct(COUNTRY)) %>%
  arrange(desc(Distinct_INFMOR)) %>%
  slice(1:5))
(INFMOR_Unique_Country <- DPA[round(DPA$INFMOR,digits=1)==30.2,c("COUNTRY")])

DPA %>%
  group_by(CLTECH) %>%
  summarize(Distinct_CLTECH = n_distinct(COUNTRY)) %>%
  arrange(desc(Distinct_CLTECH)) %>%
  slice(1:5)
(CLTECH_Unique_Country <- DPA[round(DPA$CLTECH,digits=1)==60.6,c("COUNTRY")])

DPA %>%
  group_by(RTIMOR) %>%
  summarize(Distinct_RTIMOR = n_distinct(COUNTRY)) %>%
  arrange(desc(Distinct_RTIMOR)) %>%
  slice(1:5)
(RTIMOR_Unique_Country <- DPA[round(DPA$RTIMOR,digits=1)==18.2,c("COUNTRY")])

DPA %>%
  group_by(DPTIMM) %>%
  summarize(Distinct_DPTIMM = n_distinct(COUNTRY)) %>%
  arrange(desc(Distinct_DPTIMM)) %>%
  slice(1:5)
(DPTIMM_Unique_Country <- DPA[round(DPA$DPTIMM,digits=1)==85.7,c("COUNTRY")])

DPA %>%
  group_by(HEPIMM) %>%
  summarize(Distinct_HEPIMM = n_distinct(COUNTRY)) %>%
  arrange(desc(Distinct_HEPIMM)) %>%
  slice(1:5)
(HEPIMM_Unique_Country <- DPA[round(DPA$HEPIMM,digits=1)==81.3,c("COUNTRY")])

DPA %>%
  group_by(MEAIMM) %>%
  summarize(Distinct_MEAIMM = n_distinct(COUNTRY)) %>%
  arrange(desc(Distinct_MEAIMM)) %>%
  slice(1:5)
(MEAIMM_Unique_Country <- DPA[round(DPA$MEAIMM,digits=1)==84.9,c("COUNTRY")])

DPA %>%
  group_by(HOSBED) %>%
  summarize(Distinct_HOSBED = n_distinct(COUNTRY)) %>%
  arrange(desc(Distinct_HOSBED)) %>%
  slice(1:5)
(HOSBED_Unique_Country <- DPA[round(DPA$HOSBED,digits=1)==3.0,c("COUNTRY")])

DPA %>%
  group_by(NCOMOR) %>%
  summarize(Distinct_NCOMOR = n_distinct(COUNTRY)) %>%
  arrange(desc(Distinct_NCOMOR)) %>%
  slice(1:5)
(NCOMOR_Unique_Country <- DPA[round(DPA$NCOMOR,digits=1)==22.1,c("COUNTRY")])

DPA %>%
  group_by(SUIRAT) %>%
  summarize(Distinct_SUIRAT = n_distinct(COUNTRY)) %>%
  arrange(desc(Distinct_SUIRAT)) %>%
  slice(1:5)
(SUIRAT_Unique_Country <- DPA[round(DPA$SUIRAT,digits=1)==10.6,c("COUNTRY")])

(AnomalousVariables_Unique_Country <- MEAIMM_Unique_Country)

##################################
# Removing associated rows associated
# with anomalous variables
##################################
dim(DPA)

DPA <- DPA[!(DPA$COUNTRY %in% AnomalousVariables_Unique_Country),]
dim(DPA)

##################################
# Listing all Predictors
# for the updated data
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("COUNTRY","YEAR","LIFEXP")]

##################################
# Listing all numeric predictors
# for the updated data
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

```

```{r section_1.3.3.3, warning=FALSE, message=FALSE}
##################################
# Zero and Near-Zero Variance
##################################

##################################
# Identifying columns with low variance
###################################
DPA_LowVariance <- nearZeroVar(DPA,
                               freqCut = 80/20,
                               uniqueCut = 10,
                               saveMetrics= TRUE)
(DPA_LowVariance[DPA_LowVariance$nzv,])

if ((nrow(DPA_LowVariance[DPA_LowVariance$nzv,]))==0){
  
  print("No low variance predictors noted.")
  
} else {

  print(paste0("Low variance observed for ",
               (nrow(DPA_LowVariance[DPA_LowVariance$nzv,])),
               " numeric variable(s) with First.Second.Mode.Ratio>4 and Unique.Count.Ratio<0.10."))
  
  DPA_LowVarianceForRemoval <- (nrow(DPA_LowVariance[DPA_LowVariance$nzv,]))
  
  print(paste0("Low variance can be resolved by removing ",
               (nrow(DPA_LowVariance[DPA_LowVariance$nzv,])),
               " numeric variable(s)."))
  
  for (j in 1:DPA_LowVarianceForRemoval) {
  DPA_LowVarianceRemovedVariable <- rownames(DPA_LowVariance[DPA_LowVariance$nzv,])[j]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_LowVarianceRemovedVariable))
  }
  
  DPA %>%
  skim() %>%
  dplyr::filter(skim_variable %in% rownames(DPA_LowVariance[DPA_LowVariance$nzv,]))

}

```

```{r section_1.3.3.4, warning=FALSE, message=FALSE}
##################################
# Collinearity
##################################

##################################
# Visualizing pairwise correlation between predictors
##################################
DPA_CorrelationTest <- cor.mtest(DPA.Predictors.Numeric,
                       method = "pearson",
                       conf.level = .95)

corrplot(cor(DPA.Predictors.Numeric,
             method = "pearson",
             use="pairwise.complete.obs"), 
         method = "circle",
         type = "upper", 
         order = "original", 
         tl.col = "black", 
         tl.cex = 0.75,
         tl.srt = 90, 
         sig.level = 0.05, 
         p.mat = DPA_CorrelationTest$p,
         insig = "blank")

##################################
# Identifying the highly correlated variables
##################################
DPA_Correlation <-  cor(DPA.Predictors.Numeric, 
                        method = "pearson",
                        use="pairwise.complete.obs")
(DPA_HighlyCorrelatedCount <- sum(abs(DPA_Correlation[upper.tri(DPA_Correlation)]) > 0.75))

if (DPA_HighlyCorrelatedCount == 0) {
  print("No highly correlated predictors noted.")
} else {
  print(paste0("High correlation observed for ",
               (DPA_HighlyCorrelatedCount),
               " pairs of numeric variable(s) with Correlation.Coefficient>0.75."))
  
  (DPA_HighlyCorrelatedPairs <- corr_cross(DPA.Predictors.Numeric,
  max_pvalue = 0.05, 
  top = DPA_HighlyCorrelatedCount,
  rm.na = TRUE,
  grid = FALSE
))
  
}

if (DPA_HighlyCorrelatedCount > 0) {
  DPA_HighlyCorrelated <- findCorrelation(DPA_Correlation, cutoff = 0.75)
  
  (DPA_HighlyCorrelatedForRemoval <- length(DPA_HighlyCorrelated))
  
  print(paste0("High correlation can be resolved by removing ",
               (DPA_HighlyCorrelatedForRemoval),
               " numeric variable(s)."))
  
  for (j in 1:DPA_HighlyCorrelatedForRemoval) {
  DPA_HighlyCorrelatedRemovedVariable <- colnames(DPA.Predictors.Numeric)[DPA_HighlyCorrelated[j]]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_HighlyCorrelatedRemovedVariable))
  }
  
}

```

```{r section_1.3.3.5, warning=FALSE, message=FALSE}
##################################
# Linear Dependencies
##################################

##################################
# Finding linear dependencies
##################################
DPA_LinearlyDependent <- findLinearCombos(DPA.Predictors.Numeric)

##################################
# Identifying the linearly dependent variables
##################################
DPA_LinearlyDependent <- findLinearCombos(DPA.Predictors.Numeric)

(DPA_LinearlyDependentCount <- length(DPA_LinearlyDependent$linearCombos))

if (DPA_LinearlyDependentCount == 0) {
  print("No linearly dependent predictors noted.")
} else {
  print(paste0("Linear dependency observed for ",
               (DPA_LinearlyDependentCount),
               " subset(s) of numeric variable(s)."))
  
  for (i in 1:DPA_LinearlyDependentCount) {
    DPA_LinearlyDependentSubset <- colnames(DPA.Predictors.Numeric)[DPA_LinearlyDependent$linearCombos[[i]]]
    print(paste0("Linear dependent variable(s) for subset ",
                 i,
                 " include: ",
                 DPA_LinearlyDependentSubset))
  }
  
}

##################################
# Identifying the linearly dependent variables for removal
##################################

if (DPA_LinearlyDependentCount > 0) {
  DPA_LinearlyDependent <- findLinearCombos(DPA.Predictors.Numeric)
  
  DPA_LinearlyDependentForRemoval <- length(DPA_LinearlyDependent$remove)
  
  print(paste0("Linear dependency can be resolved by removing ",
               (DPA_LinearlyDependentForRemoval),
               " numeric variable(s)."))
  
  for (j in 1:DPA_LinearlyDependentForRemoval) {
  DPA_LinearlyDependentRemovedVariable <- colnames(DPA.Predictors.Numeric)[DPA_LinearlyDependent$remove[j]]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_LinearlyDependentRemovedVariable))
  }

}

```

```{r section_1.3.3.6, warning=FALSE, message=FALSE, fig.width=15, fig.height=2}
##################################
# Shape Transformation
##################################

##################################
# Applying a Box-Cox transformation
##################################
DPA_BoxCox <- preProcess(DPA.Predictors.Numeric, method = c("BoxCox"))
DPA_BoxCoxTransformed <- predict(DPA_BoxCox, DPA.Predictors.Numeric)

for (i in 1:ncol(DPA_BoxCoxTransformed)) {
  Median <- format(round(median(DPA_BoxCoxTransformed[,i],na.rm = TRUE),2), nsmall=2)
  Mean <- format(round(mean(DPA_BoxCoxTransformed[,i],na.rm = TRUE),2), nsmall=2)
  Skewness <- format(round(skewness(DPA_BoxCoxTransformed[,i],na.rm = TRUE),2), nsmall=2)
  print(
  ggplot(DPA_BoxCoxTransformed, aes(x=DPA_BoxCoxTransformed[,i])) +
  geom_histogram(binwidth=1,color="black", fill="white") +
  geom_vline(aes(xintercept=mean(DPA_BoxCoxTransformed[,i])),
            color="blue", size=1) +
    geom_vline(aes(xintercept=median(DPA_BoxCoxTransformed[,i])),
            color="red", size=1) +
  theme_bw() +
  ylab("Count") +
  xlab(names(DPA_BoxCoxTransformed)[i]) +
  labs(title=names(DPA_BoxCoxTransformed)[i],
       subtitle=paste0("Median = ", Median,
                       ", Mean = ", Mean,
                       ", Skewness = ", Skewness)))
}

DPA_BoxCoxTransformed <- cbind(DPA_BoxCoxTransformed,DPA[,c("COUNTRY",
                                                            "YEAR",
                                                            "GENDER",
                                                            "LIFEXP")])

```

```{r section_1.3.3.7, warning=FALSE, message=FALSE}
##################################
# Creating the pre-modelling
# train set
##################################
PMA <- DPA_BoxCoxTransformed[,!names(DPA_BoxCoxTransformed) %in% c("YEAR",
                                                                   "GNI",
                                                                   "DPTIMM",
                                                                   "MEAIMM",
                                                                   "RURPOP",
                                                                   "SANSER",
                                                                   "RTIMOR")]

##################################
# Gathering descriptive statistics
##################################
(PMA_Skimmed <- skim(PMA))

```

</details>

###  1.3.4 Data Exploration
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.4, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
PME <- PMA
PME.Numeric <- PME[,sapply(PME, is.numeric), drop = FALSE]

##################################
# Listing all Predictors
##################################
PME.Predictors <- PME[,!names(PME) %in% c("COUNTRY","LIFEXP")]

##################################
# Listing all numeric Predictors
##################################
PME.Predictors.Numeric <- PME.Predictors[,sapply(PME.Predictors, is.numeric), drop = FALSE]
ncol(PME.Predictors.Numeric)

##################################
# Listing all numeric Predictors
##################################
PME.Predictors.Factor <- PME.Predictors[,sapply(PME.Predictors, is.factor), drop = FALSE]
ncol(PME.Predictors.Factor)

##################################
# Formulating the scatter plot
##################################
featurePlot(x = PME.Predictors.Numeric, 
            y = PME$LIFEXP,
            plot = "scatter",
            type = c("p", "smooth"),
            span = .5,
            layout = c(4, 3))

##################################
# Formulating the box plot
##################################
featurePlot(x = PME.Numeric, 
            y = PME$GENDER,
            plot = "box",
            scales = list(x = list(relation="free", rot = 90), 
                          y = list(relation="free")),
            adjust = 1.5,
            layout = c(4, 4))

```

</details>

###  1.3.5 Feature Selection
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.5, warning=FALSE, message=FALSE}
##################################
# Evaluating model-independent
# feature importance metrics
##################################

##################################
# Obtaining the LOWESSPR pseudo-R-Squared
##################################
FE_LOWESSPR <- filterVarImp(x = PME.Numeric[,!names(PME.Numeric) %in% c("LIFEXP")],
                            y = PME$LIFEXP,
                            nonpara = TRUE)

##################################
# Formulating the summary table
##################################
FE_LOWESSPR_Summary <- FE_LOWESSPR 

FE_LOWESSPR_Summary$Predictor <- rownames(FE_LOWESSPR)
names(FE_LOWESSPR_Summary)[1] <- "LOWESSPR"
FE_LOWESSPR_Summary$Metric <- rep("LOWESSPR",nrow(FE_LOWESSPR))

FE_LOWESSPR_Summary

##################################
# Exploring predictor performance
# using LOWESS
##################################
dotplot(Predictor ~ LOWESSPR | Metric, 
        FE_LOWESSPR_Summary,
        origin = 0,
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })

##################################
# Obtaining the Pearson correlation coefficient
##################################
(FE_PCC <- abs(cor(PME.Numeric, method="pearson")[-13,13]))

##################################
# Formulating the summary table
##################################
FE_PCC_Summary <- data.frame(Predictor = names(PME.Numeric)[1:(ncol(PME.Numeric)-1)],
                             PCC = FE_PCC,
                             Metric = rep("PCC", length(FE_PCC)))

FE_PCC_Summary

##################################
# Exploring predictor performance
# using PCC
##################################
dotplot(Predictor ~ PCC | Metric, 
        FE_PCC_Summary,
        origin = 0,
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })

##################################
# Obtaining the Spearman's rank correlation coefficient
##################################
(FE_SRCC <- abs(cor(PME.Numeric, method="spearman")[-13,13]))

##################################
# Formulating the summary table
##################################
FE_SRCC_Summary <- data.frame(Predictor = names(PME.Numeric)[1:(ncol(PME.Numeric)-1)],
                             SRCC = FE_SRCC,
                             Metric = rep("SRCC", length(FE_SRCC)))

FE_SRCC_Summary

##################################
# Exploring predictor performance
# using SRCC
##################################
dotplot(Predictor ~ SRCC | Metric, 
        FE_SRCC_Summary,
        origin = 0,
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })

##################################
# Obtaining the maximal information coefficient
##################################
FE_MIC <- mine(x = PME.Numeric[,!names(PME.Numeric) %in% c("LIFEXP")],
               y = PME$LIFEXP)$MIC

##################################
# Formulating the summary table
##################################
FE_MIC_Summary <- data.frame(Predictor = names(PME.Numeric)[1:(ncol(PME.Numeric)-1)],
                             MIC = FE_MIC[,1],
                             Metric = rep("MIC", length(FE_MIC)))

FE_MIC_Summary

##################################
# Exploring predictor performance
# using MIC
##################################
dotplot(Predictor ~ MIC | Metric, 
        FE_MIC_Summary,
        origin = 0,
        type = c("p", "h"),
        pch = 16,
        cex = 2,
        alpha = 0.45,
        prepanel = function(x, y) {
            list(ylim = levels(reorder(y, x)))
        },
        panel = function(x, y, ...) {
            panel.dotplot(x, reorder(y, x), ...)
        })

```

</details>

###  1.3.6 Model Development
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.6, warning=FALSE, message=FALSE}


```

</details>

###  1.3.7 Model Selection
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.7, warning=FALSE, message=FALSE}


```

</details>

###  1.3.8 Model Performance Estimation
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.8, warning=FALSE, message=FALSE}


```

</details>

###  1.3.9 Model Performance Validation
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.9, warning=FALSE, message=FALSE}


```

</details>

###  1.3.10 Model Post-Hoc Analysis
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.10, warning=FALSE, message=FALSE}


```

</details>

##  1.4 Summary
|
# **2. References**
|
| **[Book]** [Explanatory Model Analysis: Explore, Explain, and Examine Predictive Models With examples in R and Python](https://ema.drwhy.ai/) by Przemyslaw Biecek and Tomasz Burzykowski
| **[Book]** [Explainable Machine Learning: A Guide for Making Black Box Models Explainable](https://christophm.github.io/interpretable-ml-book/) by Christoph Molnar
| **[Book]** [Explainable AI: Interpreting, Explaining and Visualizing Deep Learning](https://link.springer.com/book/10.1007/978-3-030-28954-6) by Wojciech Samek, Gregoire Montavon, Andrea Vedaldi, Lars Kai Hansen and Klaus-Robert Muller
| **[R Package]** [DALEX](https://cran.r-project.org/web/packages/DALEX/index.html) by Przemyslaw Biecek, Szymon Maksymiuk and Hubert Baniecki
| **[R Package]** [iml](https://cran.r-project.org/web/packages/iml/index.html) by Christoph Molnar
| **[R Package]** [ALEPlot](https://cran.r-project.org/web/packages/ALEPlot/index.html) by Dan Apley
| **[R Package]** [randomForest](https://cran.r-project.org/web/packages/randomForest/index.html) by Leo Breiman, Adele Cutler, Andy Liaw and Matthew Wiener
| **[R Package]** [auditor](https://cran.r-project.org/web/packages/auditor/index.html) by Alicja Gosiewska, Przemyslaw Biecek, Hubert Baniecki and Tomasz Mikołajczyk
| **[R Package]** [fastshap](https://cran.r-project.org/web/packages/fastshap/index.html) by Brandon Greenwell
| **[R Package]** [rms](https://cran.r-project.org/web/packages/rms/index.html) by Frank Harrell
| **[R Package]** [EIX](https://cran.r-project.org/web/packages/EIX/index.html) by Szymon Maksymiuk, Ewelina Karbowiak and Przemyslaw Biecek
| **[R Package]** [parsnip](https://cran.r-project.org/web/packages/parsnip/index.html) by Max Kuhn and Davis Vaughan 
| **[R Package]** [h2o](https://cran.r-project.org/web/packages/h2o/index.html) by Tomas Fryda, Erin LeDell, Navdeep Gill, Spencer Aiello, Anqi Fu, Arno Candel, Cliff Click, Tom Kraljevic, Tomas Nykodym, Patrick Aboyoun, Michal Kurka, Michal Malohlava, Sebastien Poirier and Wendy Wong
| **[R Package]** [tidymodels](https://cran.r-project.org/web/packages/tidymodels/index.html) by Max Kuhn and Hadley Wickham 
| **[R Package]** [e1071](https://cran.r-project.org/web/packages/e1071/index.html) by David Meyer, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel and Friedrich Leisch
| **[R Package]** [lime](https://cran.r-project.org/web/packages/lime/index.html) by Emil Hvitfeldt, Thomas Lin Pedersen and Michael Benesty
| **[R Package]** [gbm](https://cran.r-project.org/web/packages/gbm/index.html) by Brandon Greenwell, Bradley Boehmke, Jay Cunningham and GBM Developers
| **[R Package]** [ExplainPrediction](https://cran.r-project.org/web/packages/ExplainPrediction/index.html) by Marko Robnik-Sikonja
| **[R Package]** [localModel](https://cran.r-project.org/web/packages/localModel/index.html) by Przemyslaw Biecek and Mateusz Staniak
| **[R Package]** [skimr](https://cran.r-project.org/web/packages/skimr/skimr.pdf) by  Elin Waring
| **[R Package]** [corrplot](https://cran.r-project.org/web/packages/corrplot/corrplot.pdf) by Taiyun Wei
| **[R Package]** [lares](https://cran.rstudio.com/web/packages/lares/lares.pdf) by Bernardo Lares
| **[Article]** [Interpretation Methods for Black-Box Machine Learning Models in Insurance Rating-Type Applications ](https://support.sas.com/resources/papers/proceedings20/5116-2020.pdf) by Gabe Taylor, Sunish Menon, Huimin Ru, Ray Wright, Xin Hunt and Ralph Abbey
| **[Article]** [4 Model-Agnostic Interpretability Techniques for Complex Models ](https://blogs.sas.com/content/subconsciousmusings/2020/05/07/model-agnostic-interpretability/) by Funda Gunes
| **[Article]** [How Can We Provide Post-Hoc Explanations for Black-Box AI Models? ](https://aisingapore.github.io/ai-practitioner-handbook/book/6-modelling/post-hoc-explanation.html) by Joy Lin
| **[Publication]** [A Survey of Methods for Explaining Black Box Models](https://dl.acm.org/doi/10.1145/3236009) by Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti and Dino Pedreschi (ACM Computing Surveys)
| **[Publication]** [iml: An R package for Interpretable Machine Learning](https://doi.org/10.21105/joss.00786) by Christoph Molnar (Journal of Open Source Software)
|
|
|
|
